2024-12-17 18:39:26 Training with configuration:
2024-12-17 18:39:26 data:
2024-12-17 18:39:26   colormode: RGB
2024-12-17 18:39:26   inference:
2024-12-17 18:39:26     normalize_images: True
2024-12-17 18:39:26   train:
2024-12-17 18:39:26     affine:
2024-12-17 18:39:26       p: 0.5
2024-12-17 18:39:26       rotation: 30
2024-12-17 18:39:26       scaling: [1.0, 1.0]
2024-12-17 18:39:26       translation: 0
2024-12-17 18:39:26     collate:
2024-12-17 18:39:26       type: ResizeFromDataSizeCollate
2024-12-17 18:39:26       min_scale: 0.4
2024-12-17 18:39:26       max_scale: 1.0
2024-12-17 18:39:26       min_short_side: 128
2024-12-17 18:39:26       max_short_side: 1152
2024-12-17 18:39:26       multiple_of: 32
2024-12-17 18:39:26       to_square: False
2024-12-17 18:39:26     covering: False
2024-12-17 18:39:26     gaussian_noise: 12.75
2024-12-17 18:39:26     hist_eq: False
2024-12-17 18:39:26     motion_blur: False
2024-12-17 18:39:26     normalize_images: True
2024-12-17 18:39:26 device: auto
2024-12-17 18:39:26 metadata:
2024-12-17 18:39:26   project_path: /Users/isogawaryou/CS_Animatronics/src/DeepLabCut/Animatronics-Ryo-2024-12-17
2024-12-17 18:39:26   pose_config_path: /Users/isogawaryou/CS_Animatronics/src/DeepLabCut/Animatronics-Ryo-2024-12-17/dlc-models-pytorch/iteration-0/AnimatronicsDec17-trainset95shuffle1/train/pytorch_config.yaml
2024-12-17 18:39:26   bodyparts: ['bodypart1', 'bodypart2', 'bodypart3', 'objectA']
2024-12-17 18:39:26   unique_bodyparts: []
2024-12-17 18:39:26   individuals: ['animal']
2024-12-17 18:39:26   with_identity: None
2024-12-17 18:39:26 method: bu
2024-12-17 18:39:26 model:
2024-12-17 18:39:26   backbone:
2024-12-17 18:39:26     type: ResNet
2024-12-17 18:39:26     model_name: resnet50_gn
2024-12-17 18:39:26     output_stride: 16
2024-12-17 18:39:26     freeze_bn_stats: True
2024-12-17 18:39:26     freeze_bn_weights: False
2024-12-17 18:39:26   backbone_output_channels: 2048
2024-12-17 18:39:26   heads:
2024-12-17 18:39:26     bodypart:
2024-12-17 18:39:26       type: HeatmapHead
2024-12-17 18:39:26       weight_init: normal
2024-12-17 18:39:26       predictor:
2024-12-17 18:39:26         type: HeatmapPredictor
2024-12-17 18:39:26         apply_sigmoid: False
2024-12-17 18:39:26         clip_scores: True
2024-12-17 18:39:26         location_refinement: True
2024-12-17 18:39:26         locref_std: 7.2801
2024-12-17 18:39:26       target_generator:
2024-12-17 18:39:26         type: HeatmapGaussianGenerator
2024-12-17 18:39:26         num_heatmaps: 4
2024-12-17 18:39:26         pos_dist_thresh: 17
2024-12-17 18:39:26         heatmap_mode: KEYPOINT
2024-12-17 18:39:26         gradient_masking: False
2024-12-17 18:39:26         generate_locref: True
2024-12-17 18:39:26         locref_std: 7.2801
2024-12-17 18:39:26       criterion:
2024-12-17 18:39:26         heatmap:
2024-12-17 18:39:26           type: WeightedMSECriterion
2024-12-17 18:39:26           weight: 1.0
2024-12-17 18:39:26         locref:
2024-12-17 18:39:26           type: WeightedHuberCriterion
2024-12-17 18:39:26           weight: 0.05
2024-12-17 18:39:26       heatmap_config:
2024-12-17 18:39:26         channels: [2048, 4]
2024-12-17 18:39:26         kernel_size: [3]
2024-12-17 18:39:26         strides: [2]
2024-12-17 18:39:26       locref_config:
2024-12-17 18:39:26         channels: [2048, 8]
2024-12-17 18:39:26         kernel_size: [3]
2024-12-17 18:39:26         strides: [2]
2024-12-17 18:39:26 net_type: resnet_50
2024-12-17 18:39:26 runner:
2024-12-17 18:39:26   type: PoseTrainingRunner
2024-12-17 18:39:26   gpus: None
2024-12-17 18:39:26   key_metric: test.mAP
2024-12-17 18:39:26   key_metric_asc: True
2024-12-17 18:39:26   eval_interval: 10
2024-12-17 18:39:26   optimizer:
2024-12-17 18:39:26     type: AdamW
2024-12-17 18:39:26     params:
2024-12-17 18:39:26       lr: 0.0001
2024-12-17 18:39:26   scheduler:
2024-12-17 18:39:26     type: LRListScheduler
2024-12-17 18:39:26     params:
2024-12-17 18:39:26       lr_list: [[1e-05], [1e-06]]
2024-12-17 18:39:26       milestones: [160, 190]
2024-12-17 18:39:26   snapshots:
2024-12-17 18:39:26     max_snapshots: 5
2024-12-17 18:39:26     save_epochs: 50
2024-12-17 18:39:26     save_optimizer_state: False
2024-12-17 18:39:26 train_settings:
2024-12-17 18:39:26   batch_size: 1
2024-12-17 18:39:26   dataloader_workers: 0
2024-12-17 18:39:26   dataloader_pin_memory: False
2024-12-17 18:39:26   display_iters: 1000
2024-12-17 18:39:26   epochs: 200
2024-12-17 18:39:26   seed: 42
2024-12-17 18:39:26 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2024-12-17 18:39:37 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-17 18:39:37 Data Transforms:
2024-12-17 18:39:37   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2024-12-17 18:39:37   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2024-12-17 18:39:37 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2024-12-17 18:39:37 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2024-12-17 18:39:37 Using 19 images and 1 for testing
2024-12-17 18:39:37 
Starting pose model training...
--------------------------------------------------
2024-12-17 18:40:29 Epoch 1/200 (lr=0.0001), train loss 0.01338
2024-12-17 18:41:16 Epoch 2/200 (lr=0.0001), train loss 0.00790
2024-12-17 18:42:04 Epoch 3/200 (lr=0.0001), train loss 0.00524
2024-12-17 18:42:48 Epoch 4/200 (lr=0.0001), train loss 0.00327
2024-12-17 18:43:44 Epoch 5/200 (lr=0.0001), train loss 0.00301
2024-12-17 18:44:25 Epoch 6/200 (lr=0.0001), train loss 0.00233
2024-12-17 18:45:11 Epoch 7/200 (lr=0.0001), train loss 0.00196
2024-12-17 18:45:52 Epoch 8/200 (lr=0.0001), train loss 0.00141
2024-12-17 18:46:32 Epoch 9/200 (lr=0.0001), train loss 0.00207
2024-12-17 18:47:19 Training for epoch 10 done, starting evaluation
2024-12-17 18:47:24 Epoch 10/200 (lr=0.0001), train loss 0.00161, valid loss 0.00135
2024-12-17 18:47:24 Model performance:
2024-12-17 18:47:24   metrics/test.rmse:                    206.99
2024-12-17 18:47:24   metrics/test.rmse_pcutoff:            409.11
2024-12-17 18:47:24   metrics/test.mAP:                      50.00
2024-12-17 18:47:24   metrics/test.mAR:                      50.00
2024-12-17 18:47:24   metrics/test.rmse_detections:         206.99
2024-12-17 18:47:24   metrics/test.rmse_detections_pcutoff: 409.11
2024-12-17 18:48:02 Epoch 11/200 (lr=0.0001), train loss 0.00166
2024-12-17 18:48:43 Epoch 12/200 (lr=0.0001), train loss 0.00204
2024-12-17 18:49:29 Epoch 13/200 (lr=0.0001), train loss 0.00127
2024-12-17 18:50:11 Epoch 14/200 (lr=0.0001), train loss 0.00150
2024-12-17 18:51:01 Epoch 15/200 (lr=0.0001), train loss 0.00147
2024-12-17 18:51:41 Epoch 16/200 (lr=0.0001), train loss 0.00147
2024-12-17 18:52:28 Epoch 17/200 (lr=0.0001), train loss 0.00115
2024-12-17 18:53:08 Epoch 18/200 (lr=0.0001), train loss 0.00091
2024-12-17 18:53:50 Epoch 19/200 (lr=0.0001), train loss 0.00106
2024-12-17 18:54:57 Training for epoch 20 done, starting evaluation
2024-12-17 18:55:01 Epoch 20/200 (lr=0.0001), train loss 0.00104, valid loss 0.00110
2024-12-17 18:55:01 Model performance:
2024-12-17 18:55:01   metrics/test.rmse:                    206.75
2024-12-17 18:55:01   metrics/test.rmse_pcutoff:            411.31
2024-12-17 18:55:01   metrics/test.mAP:                      50.00
2024-12-17 18:55:01   metrics/test.mAR:                      50.00
2024-12-17 18:55:01   metrics/test.rmse_detections:         206.75
2024-12-17 18:55:01   metrics/test.rmse_detections_pcutoff: 411.31
2024-12-17 18:55:57 Epoch 21/200 (lr=0.0001), train loss 0.00092
2024-12-17 18:56:43 Epoch 22/200 (lr=0.0001), train loss 0.00122
2024-12-17 18:57:31 Epoch 23/200 (lr=0.0001), train loss 0.00126
2024-12-17 18:58:20 Epoch 24/200 (lr=0.0001), train loss 0.00100
2024-12-17 18:59:01 Epoch 25/200 (lr=0.0001), train loss 0.00081
2024-12-17 18:59:50 Epoch 26/200 (lr=0.0001), train loss 0.00085
2024-12-17 19:00:46 Epoch 27/200 (lr=0.0001), train loss 0.00077
2024-12-17 19:01:32 Epoch 28/200 (lr=0.0001), train loss 0.00095
2024-12-17 19:02:15 Epoch 29/200 (lr=0.0001), train loss 0.00082
2024-12-17 19:02:53 Training for epoch 30 done, starting evaluation
2024-12-17 19:02:57 Epoch 30/200 (lr=0.0001), train loss 0.00076, valid loss 0.00156
2024-12-17 19:02:57 Model performance:
2024-12-17 19:02:57   metrics/test.rmse:                    207.12
2024-12-17 19:02:57   metrics/test.rmse_pcutoff:            411.02
2024-12-17 19:02:57   metrics/test.mAP:                      50.00
2024-12-17 19:02:57   metrics/test.mAR:                      50.00
2024-12-17 19:02:57   metrics/test.rmse_detections:         207.12
2024-12-17 19:02:57   metrics/test.rmse_detections_pcutoff: 411.02
2024-12-17 19:03:36 Epoch 31/200 (lr=0.0001), train loss 0.00074
2024-12-17 19:04:22 Epoch 32/200 (lr=0.0001), train loss 0.00062
2024-12-17 19:05:00 Epoch 33/200 (lr=0.0001), train loss 0.00088
2024-12-17 19:05:39 Epoch 34/200 (lr=0.0001), train loss 0.00091
2024-12-17 19:06:17 Epoch 35/200 (lr=0.0001), train loss 0.00083
2024-12-17 19:07:12 Epoch 36/200 (lr=0.0001), train loss 0.00075
2024-12-17 19:07:58 Epoch 37/200 (lr=0.0001), train loss 0.00072
2024-12-17 19:08:55 Epoch 38/200 (lr=0.0001), train loss 0.00066
2024-12-17 19:09:59 Epoch 39/200 (lr=0.0001), train loss 0.00084
2024-12-17 19:11:08 Training for epoch 40 done, starting evaluation
2024-12-17 19:11:12 Epoch 40/200 (lr=0.0001), train loss 0.00069, valid loss 0.00051
2024-12-17 19:11:12 Model performance:
2024-12-17 19:11:12   metrics/test.rmse:                    204.92
2024-12-17 19:11:12   metrics/test.rmse_pcutoff:            407.84
2024-12-17 19:11:12   metrics/test.mAP:                      50.00
2024-12-17 19:11:12   metrics/test.mAR:                      50.00
2024-12-17 19:11:12   metrics/test.rmse_detections:         204.92
2024-12-17 19:11:12   metrics/test.rmse_detections_pcutoff: 407.84
2024-12-17 19:11:52 Epoch 41/200 (lr=0.0001), train loss 0.00068
2024-12-17 19:12:30 Epoch 42/200 (lr=0.0001), train loss 0.00063
2024-12-17 19:13:19 Epoch 43/200 (lr=0.0001), train loss 0.00041
2024-12-17 19:14:03 Epoch 44/200 (lr=0.0001), train loss 0.00058
2024-12-17 19:14:45 Epoch 45/200 (lr=0.0001), train loss 0.00066
2024-12-17 19:15:27 Epoch 46/200 (lr=0.0001), train loss 0.00070
2024-12-17 19:16:16 Epoch 47/200 (lr=0.0001), train loss 0.00079
2024-12-17 19:16:59 Epoch 48/200 (lr=0.0001), train loss 0.00058
2024-12-17 19:17:36 Epoch 49/200 (lr=0.0001), train loss 0.00048
2024-12-17 19:18:15 Training for epoch 50 done, starting evaluation
2024-12-17 19:18:19 Epoch 50/200 (lr=0.0001), train loss 0.00056, valid loss 0.00048
2024-12-17 19:18:19 Model performance:
2024-12-17 19:18:19   metrics/test.rmse:                    205.25
2024-12-17 19:18:19   metrics/test.rmse_pcutoff:            409.22
2024-12-17 19:18:19   metrics/test.mAP:                      50.00
2024-12-17 19:18:19   metrics/test.mAR:                      50.00
2024-12-17 19:18:19   metrics/test.rmse_detections:         205.25
2024-12-17 19:18:19   metrics/test.rmse_detections_pcutoff: 409.22
2024-12-17 19:19:01 Epoch 51/200 (lr=0.0001), train loss 0.00051
2024-12-17 19:19:41 Epoch 52/200 (lr=0.0001), train loss 0.00047
2024-12-17 19:20:18 Epoch 53/200 (lr=0.0001), train loss 0.00062
2024-12-17 19:20:51 Epoch 54/200 (lr=0.0001), train loss 0.00044
2024-12-17 19:21:28 Epoch 55/200 (lr=0.0001), train loss 0.00043
2024-12-17 19:22:05 Epoch 56/200 (lr=0.0001), train loss 0.00043
2024-12-17 19:22:47 Epoch 57/200 (lr=0.0001), train loss 0.00053
2024-12-17 19:23:27 Epoch 58/200 (lr=0.0001), train loss 0.00057
2024-12-17 19:24:02 Epoch 59/200 (lr=0.0001), train loss 0.00050
2024-12-17 19:24:44 Training for epoch 60 done, starting evaluation
2024-12-17 19:24:46 Epoch 60/200 (lr=0.0001), train loss 0.00053, valid loss 0.00070
2024-12-17 19:24:46 Model performance:
2024-12-17 19:24:46   metrics/test.rmse:                    205.81
2024-12-17 19:24:46   metrics/test.rmse_pcutoff:            409.80
2024-12-17 19:24:46   metrics/test.mAP:                      50.00
2024-12-17 19:24:46   metrics/test.mAR:                      50.00
2024-12-17 19:24:46   metrics/test.rmse_detections:         205.81
2024-12-17 19:24:46   metrics/test.rmse_detections_pcutoff: 409.80
2024-12-17 19:25:23 Epoch 61/200 (lr=0.0001), train loss 0.00050
2024-12-17 19:26:09 Epoch 62/200 (lr=0.0001), train loss 0.00050
2024-12-17 19:26:46 Epoch 63/200 (lr=0.0001), train loss 0.00052
2024-12-17 19:27:23 Epoch 64/200 (lr=0.0001), train loss 0.00046
2024-12-17 19:28:02 Epoch 65/200 (lr=0.0001), train loss 0.00045
2024-12-17 19:28:39 Epoch 66/200 (lr=0.0001), train loss 0.00039
2024-12-17 19:29:22 Epoch 67/200 (lr=0.0001), train loss 0.00052
2024-12-17 19:30:00 Epoch 68/200 (lr=0.0001), train loss 0.00044
2024-12-17 19:30:37 Epoch 69/200 (lr=0.0001), train loss 0.00046
2024-12-17 19:31:10 Training for epoch 70 done, starting evaluation
2024-12-17 19:31:12 Epoch 70/200 (lr=0.0001), train loss 0.00030, valid loss 0.00042
2024-12-17 19:31:12 Model performance:
2024-12-17 19:31:12   metrics/test.rmse:                    205.77
2024-12-17 19:31:12   metrics/test.rmse_pcutoff:            409.98
2024-12-17 19:31:12   metrics/test.mAP:                      50.00
2024-12-17 19:31:12   metrics/test.mAR:                      50.00
2024-12-17 19:31:12   metrics/test.rmse_detections:         205.77
2024-12-17 19:31:12   metrics/test.rmse_detections_pcutoff: 409.98
2024-12-17 19:31:49 Epoch 71/200 (lr=0.0001), train loss 0.00039
2024-12-17 19:32:31 Epoch 72/200 (lr=0.0001), train loss 0.00032
2024-12-17 19:33:15 Epoch 73/200 (lr=0.0001), train loss 0.00042
2024-12-17 19:34:01 Epoch 74/200 (lr=0.0001), train loss 0.00045
2024-12-17 19:34:44 Epoch 75/200 (lr=0.0001), train loss 0.00050
2024-12-17 19:35:21 Epoch 76/200 (lr=0.0001), train loss 0.00052
2024-12-17 19:35:56 Epoch 77/200 (lr=0.0001), train loss 0.00053
2024-12-17 19:36:35 Epoch 78/200 (lr=0.0001), train loss 0.00052
2024-12-17 19:37:14 Epoch 79/200 (lr=0.0001), train loss 0.00037
2024-12-17 19:37:54 Training for epoch 80 done, starting evaluation
2024-12-17 19:37:57 Epoch 80/200 (lr=0.0001), train loss 0.00037, valid loss 0.00081
2024-12-17 19:37:57 Model performance:
2024-12-17 19:37:57   metrics/test.rmse:                    206.52
2024-12-17 19:37:57   metrics/test.rmse_pcutoff:            411.48
2024-12-17 19:37:57   metrics/test.mAP:                      50.00
2024-12-17 19:37:57   metrics/test.mAR:                      50.00
2024-12-17 19:37:57   metrics/test.rmse_detections:         206.52
2024-12-17 19:37:57   metrics/test.rmse_detections_pcutoff: 411.48
2024-12-17 19:38:35 Epoch 81/200 (lr=0.0001), train loss 0.00051
2024-12-17 19:39:12 Epoch 82/200 (lr=0.0001), train loss 0.00058
2024-12-17 19:39:51 Epoch 83/200 (lr=0.0001), train loss 0.00044
2024-12-17 19:40:30 Epoch 84/200 (lr=0.0001), train loss 0.00058
2024-12-17 19:41:13 Epoch 85/200 (lr=0.0001), train loss 0.00058
2024-12-17 19:41:48 Epoch 86/200 (lr=0.0001), train loss 0.00031
2024-12-17 19:42:20 Epoch 87/200 (lr=0.0001), train loss 0.00050
2024-12-17 19:43:03 Epoch 88/200 (lr=0.0001), train loss 0.00044
2024-12-17 19:43:37 Epoch 89/200 (lr=0.0001), train loss 0.00051
2024-12-17 19:44:14 Training for epoch 90 done, starting evaluation
2024-12-17 19:44:16 Epoch 90/200 (lr=0.0001), train loss 0.00037, valid loss 0.00066
2024-12-17 19:44:16 Model performance:
2024-12-17 19:44:16   metrics/test.rmse:                    205.86
2024-12-17 19:44:16   metrics/test.rmse_pcutoff:            410.10
2024-12-17 19:44:16   metrics/test.mAP:                      50.00
2024-12-17 19:44:16   metrics/test.mAR:                      50.00
2024-12-17 19:44:16   metrics/test.rmse_detections:         205.86
2024-12-17 19:44:16   metrics/test.rmse_detections_pcutoff: 410.10
2024-12-17 19:44:58 Epoch 91/200 (lr=0.0001), train loss 0.00045
2024-12-17 19:45:37 Epoch 92/200 (lr=0.0001), train loss 0.00045
2024-12-17 19:46:19 Epoch 93/200 (lr=0.0001), train loss 0.00055
2024-12-17 19:46:57 Epoch 94/200 (lr=0.0001), train loss 0.00044
2024-12-17 19:47:30 Epoch 95/200 (lr=0.0001), train loss 0.00031
2024-12-17 19:48:03 Epoch 96/200 (lr=0.0001), train loss 0.00048
2024-12-17 19:48:35 Epoch 97/200 (lr=0.0001), train loss 0.00043
2024-12-17 19:49:11 Epoch 98/200 (lr=0.0001), train loss 0.00041
2024-12-17 19:49:46 Epoch 99/200 (lr=0.0001), train loss 0.00053
2024-12-17 19:50:21 Training for epoch 100 done, starting evaluation
2024-12-17 19:50:24 Epoch 100/200 (lr=0.0001), train loss 0.00038, valid loss 0.00031
2024-12-17 19:50:24 Model performance:
2024-12-17 19:50:24   metrics/test.rmse:                    204.59
2024-12-17 19:50:24   metrics/test.rmse_pcutoff:            408.75
2024-12-17 19:50:24   metrics/test.mAP:                      50.00
2024-12-17 19:50:24   metrics/test.mAR:                      50.00
2024-12-17 19:50:24   metrics/test.rmse_detections:         204.59
2024-12-17 19:50:24   metrics/test.rmse_detections_pcutoff: 408.75
2024-12-17 19:50:59 Epoch 101/200 (lr=0.0001), train loss 0.00050
2024-12-17 19:51:37 Epoch 102/200 (lr=0.0001), train loss 0.00048
2024-12-17 19:52:11 Epoch 103/200 (lr=0.0001), train loss 0.00039
2024-12-17 19:52:47 Epoch 104/200 (lr=0.0001), train loss 0.00035
2024-12-17 19:53:24 Epoch 105/200 (lr=0.0001), train loss 0.00034
2024-12-17 19:54:01 Epoch 106/200 (lr=0.0001), train loss 0.00036
2024-12-17 19:54:40 Epoch 107/200 (lr=0.0001), train loss 0.00043
2024-12-17 19:55:14 Epoch 108/200 (lr=0.0001), train loss 0.00030
2024-12-17 19:55:51 Epoch 109/200 (lr=0.0001), train loss 0.00041
2024-12-17 19:56:29 Training for epoch 110 done, starting evaluation
2024-12-17 19:56:32 Epoch 110/200 (lr=0.0001), train loss 0.00050, valid loss 0.00053
2024-12-17 19:56:32 Model performance:
2024-12-17 19:56:32   metrics/test.rmse:                    205.61
2024-12-17 19:56:32   metrics/test.rmse_pcutoff:            409.68
2024-12-17 19:56:32   metrics/test.mAP:                      50.00
2024-12-17 19:56:32   metrics/test.mAR:                      50.00
2024-12-17 19:56:32   metrics/test.rmse_detections:         205.61
2024-12-17 19:56:32   metrics/test.rmse_detections_pcutoff: 409.68
2024-12-17 19:57:03 Epoch 111/200 (lr=0.0001), train loss 0.00041
2024-12-17 19:57:41 Epoch 112/200 (lr=0.0001), train loss 0.00039
2024-12-17 19:58:24 Epoch 113/200 (lr=0.0001), train loss 0.00041
2024-12-17 19:59:06 Epoch 114/200 (lr=0.0001), train loss 0.00055
2024-12-17 19:59:44 Epoch 115/200 (lr=0.0001), train loss 0.00038
2024-12-17 20:00:23 Epoch 116/200 (lr=0.0001), train loss 0.00036
2024-12-17 20:01:02 Epoch 117/200 (lr=0.0001), train loss 0.00032
2024-12-17 20:01:37 Epoch 118/200 (lr=0.0001), train loss 0.00031
2024-12-17 20:02:15 Epoch 119/200 (lr=0.0001), train loss 0.00046
2024-12-17 20:02:51 Training for epoch 120 done, starting evaluation
2024-12-17 20:02:55 Epoch 120/200 (lr=0.0001), train loss 0.00038, valid loss 0.00035
2024-12-17 20:02:55 Model performance:
2024-12-17 20:02:55   metrics/test.rmse:                    204.47
2024-12-17 20:02:55   metrics/test.rmse_pcutoff:            407.71
2024-12-17 20:02:55   metrics/test.mAP:                      50.00
2024-12-17 20:02:55   metrics/test.mAR:                      50.00
2024-12-17 20:02:55   metrics/test.rmse_detections:         204.47
2024-12-17 20:02:55   metrics/test.rmse_detections_pcutoff: 407.71
2024-12-17 20:03:35 Epoch 121/200 (lr=0.0001), train loss 0.00052
2024-12-17 20:04:16 Epoch 122/200 (lr=0.0001), train loss 0.00032
2024-12-17 20:04:52 Epoch 123/200 (lr=0.0001), train loss 0.00030
2024-12-17 20:05:30 Epoch 124/200 (lr=0.0001), train loss 0.00033
2024-12-17 20:06:13 Epoch 125/200 (lr=0.0001), train loss 0.00038
2024-12-17 20:06:57 Epoch 126/200 (lr=0.0001), train loss 0.00046
2024-12-17 20:07:32 Epoch 127/200 (lr=0.0001), train loss 0.00043
2024-12-17 20:08:12 Epoch 128/200 (lr=0.0001), train loss 0.00045
2024-12-17 20:08:53 Epoch 129/200 (lr=0.0001), train loss 0.00035
2024-12-17 20:09:40 Training for epoch 130 done, starting evaluation
2024-12-17 20:09:44 Epoch 130/200 (lr=0.0001), train loss 0.00045, valid loss 0.00071
2024-12-17 20:09:44 Model performance:
2024-12-17 20:09:44   metrics/test.rmse:                    205.01
2024-12-17 20:09:44   metrics/test.rmse_pcutoff:            407.18
2024-12-17 20:09:44   metrics/test.mAP:                      50.00
2024-12-17 20:09:44   metrics/test.mAR:                      50.00
2024-12-17 20:09:44   metrics/test.rmse_detections:         205.01
2024-12-17 20:09:44   metrics/test.rmse_detections_pcutoff: 407.18
2024-12-17 20:10:21 Epoch 131/200 (lr=0.0001), train loss 0.00038
2024-12-17 20:11:00 Epoch 132/200 (lr=0.0001), train loss 0.00034
2024-12-17 20:11:38 Epoch 133/200 (lr=0.0001), train loss 0.00035
2024-12-17 20:12:10 Epoch 134/200 (lr=0.0001), train loss 0.00027
2024-12-17 20:12:49 Epoch 135/200 (lr=0.0001), train loss 0.00028
2024-12-17 20:13:29 Epoch 136/200 (lr=0.0001), train loss 0.00031
2024-12-17 20:14:07 Epoch 137/200 (lr=0.0001), train loss 0.00040
2024-12-17 20:14:51 Epoch 138/200 (lr=0.0001), train loss 0.00036
2024-12-17 20:15:37 Epoch 139/200 (lr=0.0001), train loss 0.00063
2024-12-17 20:16:15 Training for epoch 140 done, starting evaluation
2024-12-17 20:16:19 Epoch 140/200 (lr=0.0001), train loss 0.00031, valid loss 0.00052
2024-12-17 20:16:19 Model performance:
2024-12-17 20:16:19   metrics/test.rmse:                    205.07
2024-12-17 20:16:19   metrics/test.rmse_pcutoff:            408.78
2024-12-17 20:16:19   metrics/test.mAP:                      50.00
2024-12-17 20:16:19   metrics/test.mAR:                      50.00
2024-12-17 20:16:19   metrics/test.rmse_detections:         205.07
2024-12-17 20:16:19   metrics/test.rmse_detections_pcutoff: 408.78
2024-12-17 20:17:00 Epoch 141/200 (lr=0.0001), train loss 0.00035
2024-12-17 20:17:33 Epoch 142/200 (lr=0.0001), train loss 0.00027
2024-12-17 20:18:08 Epoch 143/200 (lr=0.0001), train loss 0.00020
2024-12-17 20:18:52 Epoch 144/200 (lr=0.0001), train loss 0.00026
2024-12-17 20:19:34 Epoch 145/200 (lr=0.0001), train loss 0.00025
2024-12-17 20:20:12 Epoch 146/200 (lr=0.0001), train loss 0.00039
2024-12-17 20:20:50 Epoch 147/200 (lr=0.0001), train loss 0.00027
2024-12-17 20:21:29 Epoch 148/200 (lr=0.0001), train loss 0.00027
2024-12-17 20:22:11 Epoch 149/200 (lr=0.0001), train loss 0.00028
2024-12-17 20:22:58 Training for epoch 150 done, starting evaluation
2024-12-17 20:23:01 Epoch 150/200 (lr=0.0001), train loss 0.00038, valid loss 0.00045
2024-12-17 20:23:01 Model performance:
2024-12-17 20:23:01   metrics/test.rmse:                    205.40
2024-12-17 20:23:01   metrics/test.rmse_pcutoff:            408.45
2024-12-17 20:23:01   metrics/test.mAP:                      50.00
2024-12-17 20:23:01   metrics/test.mAR:                      50.00
2024-12-17 20:23:01   metrics/test.rmse_detections:         205.40
2024-12-17 20:23:01   metrics/test.rmse_detections_pcutoff: 408.45
2024-12-17 20:23:48 Epoch 151/200 (lr=0.0001), train loss 0.00038
2024-12-17 20:24:29 Epoch 152/200 (lr=0.0001), train loss 0.00031
2024-12-17 20:25:13 Epoch 153/200 (lr=0.0001), train loss 0.00033
2024-12-17 20:25:57 Epoch 154/200 (lr=0.0001), train loss 0.00031
2024-12-17 20:26:40 Epoch 155/200 (lr=0.0001), train loss 0.00028
2024-12-17 20:27:18 Epoch 156/200 (lr=0.0001), train loss 0.00026
2024-12-17 20:27:56 Epoch 157/200 (lr=0.0001), train loss 0.00037
2024-12-17 20:28:35 Epoch 158/200 (lr=0.0001), train loss 0.00029
2024-12-17 20:29:21 Epoch 159/200 (lr=0.0001), train loss 0.00036
2024-12-17 20:30:00 Training for epoch 160 done, starting evaluation
2024-12-17 20:30:04 Epoch 160/200 (lr=1e-05), train loss 0.00035, valid loss 0.00058
2024-12-17 20:30:04 Model performance:
2024-12-17 20:30:04   metrics/test.rmse:                    204.80
2024-12-17 20:30:04   metrics/test.rmse_pcutoff:            407.68
2024-12-17 20:30:04   metrics/test.mAP:                      50.00
2024-12-17 20:30:04   metrics/test.mAR:                      50.00
2024-12-17 20:30:04   metrics/test.rmse_detections:         204.80
2024-12-17 20:30:04   metrics/test.rmse_detections_pcutoff: 407.68
2024-12-17 20:30:45 Epoch 161/200 (lr=1e-05), train loss 0.00026
2024-12-17 20:31:28 Epoch 162/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:32:06 Epoch 163/200 (lr=1e-05), train loss 0.00016
2024-12-17 20:32:43 Epoch 164/200 (lr=1e-05), train loss 0.00017
2024-12-17 20:33:22 Epoch 165/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:34:00 Epoch 166/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:34:45 Epoch 167/200 (lr=1e-05), train loss 0.00017
2024-12-17 20:35:27 Epoch 168/200 (lr=1e-05), train loss 0.00018
2024-12-17 20:36:05 Epoch 169/200 (lr=1e-05), train loss 0.00012
2024-12-17 20:36:45 Training for epoch 170 done, starting evaluation
2024-12-17 20:36:48 Epoch 170/200 (lr=1e-05), train loss 0.00014, valid loss 0.00035
2024-12-17 20:36:48 Model performance:
2024-12-17 20:36:48   metrics/test.rmse:                    205.06
2024-12-17 20:36:48   metrics/test.rmse_pcutoff:            408.60
2024-12-17 20:36:48   metrics/test.mAP:                      50.00
2024-12-17 20:36:48   metrics/test.mAR:                      50.00
2024-12-17 20:36:48   metrics/test.rmse_detections:         205.06
2024-12-17 20:36:48   metrics/test.rmse_detections_pcutoff: 408.60
2024-12-17 20:37:26 Epoch 171/200 (lr=1e-05), train loss 0.00016
2024-12-17 20:38:04 Epoch 172/200 (lr=1e-05), train loss 0.00016
2024-12-17 20:38:42 Epoch 173/200 (lr=1e-05), train loss 0.00016
2024-12-17 20:39:24 Epoch 174/200 (lr=1e-05), train loss 0.00018
2024-12-17 20:40:06 Epoch 175/200 (lr=1e-05), train loss 0.00013
2024-12-17 20:40:51 Epoch 176/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:41:38 Epoch 177/200 (lr=1e-05), train loss 0.00017
2024-12-17 20:42:24 Epoch 178/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:43:07 Epoch 179/200 (lr=1e-05), train loss 0.00017
2024-12-17 20:43:54 Training for epoch 180 done, starting evaluation
2024-12-17 20:43:57 Epoch 180/200 (lr=1e-05), train loss 0.00013, valid loss 0.00033
2024-12-17 20:43:57 Model performance:
2024-12-17 20:43:57   metrics/test.rmse:                    205.00
2024-12-17 20:43:57   metrics/test.rmse_pcutoff:            408.61
2024-12-17 20:43:57   metrics/test.mAP:                      50.00
2024-12-17 20:43:57   metrics/test.mAR:                      50.00
2024-12-17 20:43:57   metrics/test.rmse_detections:         205.00
2024-12-17 20:43:57   metrics/test.rmse_detections_pcutoff: 408.61
2024-12-17 20:44:43 Epoch 181/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:45:25 Epoch 182/200 (lr=1e-05), train loss 0.00016
2024-12-17 20:46:13 Epoch 183/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:47:00 Epoch 184/200 (lr=1e-05), train loss 0.00014
2024-12-17 20:47:36 Epoch 185/200 (lr=1e-05), train loss 0.00013
2024-12-17 20:48:17 Epoch 186/200 (lr=1e-05), train loss 0.00014
2024-12-17 20:48:55 Epoch 187/200 (lr=1e-05), train loss 0.00014
2024-12-17 20:49:37 Epoch 188/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:50:18 Epoch 189/200 (lr=1e-05), train loss 0.00015
2024-12-17 20:51:01 Training for epoch 190 done, starting evaluation
2024-12-17 20:51:04 Epoch 190/200 (lr=1e-06), train loss 0.00013, valid loss 0.00028
2024-12-17 20:51:04 Model performance:
2024-12-17 20:51:04   metrics/test.rmse:                    204.76
2024-12-17 20:51:04   metrics/test.rmse_pcutoff:            408.54
2024-12-17 20:51:04   metrics/test.mAP:                      50.00
2024-12-17 20:51:04   metrics/test.mAR:                      50.00
2024-12-17 20:51:04   metrics/test.rmse_detections:         204.76
2024-12-17 20:51:04   metrics/test.rmse_detections_pcutoff: 408.54
2024-12-17 20:51:43 Epoch 191/200 (lr=1e-06), train loss 0.00014
2024-12-17 20:52:19 Epoch 192/200 (lr=1e-06), train loss 0.00015
2024-12-17 20:52:58 Epoch 193/200 (lr=1e-06), train loss 0.00014
2024-12-17 20:53:29 Epoch 194/200 (lr=1e-06), train loss 0.00013
2024-12-17 20:54:08 Epoch 195/200 (lr=1e-06), train loss 0.00013
2024-12-17 20:54:43 Epoch 196/200 (lr=1e-06), train loss 0.00014
2024-12-17 20:55:21 Epoch 197/200 (lr=1e-06), train loss 0.00013
2024-12-17 20:56:07 Epoch 198/200 (lr=1e-06), train loss 0.00014
2024-12-17 20:56:50 Epoch 199/200 (lr=1e-06), train loss 0.00015
2024-12-17 20:57:29 Training for epoch 200 done, starting evaluation
2024-12-17 20:57:33 Epoch 200/200 (lr=1e-06), train loss 0.00011, valid loss 0.00030
2024-12-17 20:57:33 Model performance:
2024-12-17 20:57:33   metrics/test.rmse:                    204.85
2024-12-17 20:57:33   metrics/test.rmse_pcutoff:            408.59
2024-12-17 20:57:33   metrics/test.mAP:                      50.00
2024-12-17 20:57:33   metrics/test.mAR:                      50.00
2024-12-17 20:57:33   metrics/test.rmse_detections:         204.85
2024-12-17 20:57:33   metrics/test.rmse_detections_pcutoff: 408.59
